{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "268b0c32-2982-4833-b373-d9f39ac4369d",
   "metadata": {},
   "source": [
    "# Enhancing Non-Patient Specific ECG Classification Through Convolutional Denoising Autoencoders\n",
    "\n",
    "This code implements the paper: **Arrhythmia Detection from 2-lead ECG using Convolutional Denoising Autoencoders** written by Ochiai, Takahashi’, and Fukazawa. We mirror the methodology from the paper by first downloading the data from the MIT-BIH Ayyhythmia and NSRDB datasets.\n",
    "\n",
    "This work is submitted by: **Jay Mittal, Patrick Dowell, Alex Vo, & Joshua Barraza**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddb616-7545-4c32-9b38-af99734f38c6",
   "metadata": {},
   "source": [
    "WFDB in Python refers to the Waveform Database Software Package (WFDB) for Python, an open-source library that provides tools for reading, writing, processing, and plotting physiological signals and associated annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b23d14-3d4b-4e0b-afe1-1f332958dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692ca5b-88a3-43a0-8176-dbdfb856429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7930ae1-86ac-4149-bf3d-df416a517695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. SETUP + IMPORTS\n",
    "# =====================================================\n",
    "import os\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f47c8-f0bd-4dec-b1b4-c02de36680ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2. CONFIGURATION\n",
    "# ============================\n",
    "class Config:\n",
    "    # ----- Data paths -----\n",
    "    DATA_ROOT = \"./data\"\n",
    "    X_FILE = \"X.npy\"          # shape: (N, TIME_STEPS, NUM_LEADS)\n",
    "    Y_FILE = \"y.npy\"          # shape: (N,)\n",
    "    GROUP_FILE = \"groups.npy\" # optional: shape (N,) with patient/record IDs\n",
    "\n",
    "    # ----- Splits -----\n",
    "    TRAIN_VAL_TEST_SPLIT = (0.7, 0.15, 0.15)  # used if GROUP_FILE missing\n",
    "\n",
    "    # ----- Input shape -----\n",
    "    TIME_STEPS = 360          # samples per segment, chose 360 to match 360 Hz of MIT-BIH\n",
    "    NUM_LEADS = 2             # # of ECG leads in X\n",
    "    NUM_CLASSES = 5           # # of arrhythmia classes\n",
    "\n",
    "    # ----- Training hyperparameters -----\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 2\n",
    "\n",
    "    LR_BASELINE = 1e-3\n",
    "    LR_AE = 1e-3\n",
    "    LR_CLASSIFIER = 1e-3          # CDAE classifier learning rate (frozen phase)\n",
    "    LR_CLASSIFIER_FINE_TUNE = 5e-4  # CDAE classifier + encoder fine-tune LR\n",
    "\n",
    "    NUM_EPOCHS_BASELINE = 5   # TODO: Switch later on to 20, used 5 for quick testing\n",
    "    NUM_EPOCHS_AE = 5\n",
    "    NUM_EPOCHS_CDAE = 5\n",
    "\n",
    "    # ----- Denoising AE noise schedule -----\n",
    "    AE_NOISE_STD_MIN = 0.01\n",
    "    AE_NOISE_STD_MAX = 0.15\n",
    "\n",
    "    # ----- CDAE training schedule -----\n",
    "    CDAE_FREEZE_EPOCHS = 5   # epochs with frozen encoder at start\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "os.makedirs(cfg.DATA_ROOT, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945b2e8-7bd0-4216-9a4f-4df84579b6a2",
   "metadata": {},
   "source": [
    "**Fixed-Length Window Extraction**\n",
    "\n",
    "To transform raw ECG signals into a format suitable for deep learning, each annotated beat is converted into a 1-second window centered on the annotation index:\n",
    "- Sampling Frequency: 360 Hz\n",
    "- Window Size: 360 samples\n",
    "- Leads: 2\n",
    "\n",
    "Windows are extracted as (360, 2) arrays and stacked into a dataset of shape (N, 360, 2) where N is the number of beats kept after preprocessing.\n",
    "\n",
    "**Beat-class Mapping**\n",
    "\n",
    "Following our project proposal, we simplified annotations into 5 classes:\n",
    "\n",
    "**[Symbol(s)]\t[Class]\t[Description]** (TODO: Find a better way to format this)\n",
    "\n",
    "[N, L, R]\t[0]\t[Normal / bundle branch block]\n",
    "\n",
    "[V]\t[1]\t[Ventricular ectopic]\n",
    "\n",
    "[A]\t[2]\t[Atrial / supraventricular]\n",
    "\n",
    "[/]\t[3]\t[Paced]\n",
    "\n",
    "[F]\t[4]\t[Fusion / other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9619e-089c-47a0-ae61-3c15bd6c31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 2.5 PREPROCESSING (LIGHTWEIGHT):\n",
    "# Build X.npy, y.npy, groups.npy from existing MITDB\n",
    "# =====================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import wfdb\n",
    "\n",
    "DATA_ROOT = cfg.DATA_ROOT if hasattr(cfg, \"DATA_ROOT\") else \"./data\"\n",
    "MITDB_DIR = os.path.join(DATA_ROOT, \"mitdb\")\n",
    "\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "X_PATH = os.path.join(DATA_ROOT, \"X.npy\")\n",
    "Y_PATH = os.path.join(DATA_ROOT, \"y.npy\")\n",
    "G_PATH = os.path.join(DATA_ROOT, \"groups.npy\")\n",
    "\n",
    "# ---------- 1) Skip if already done ----------\n",
    "if os.path.exists(X_PATH) and os.path.exists(Y_PATH) and os.path.exists(G_PATH):\n",
    "    print(\"Found existing X.npy, y.npy, groups.npy — skipping preprocessing.\")\n",
    "else:\n",
    "    print(\"No preprocessed arrays found. Building X.npy, y.npy, groups.npy from MITDB only.\")\n",
    "\n",
    "    # ---------- 2) Basic parameters ----------\n",
    "    FS = 360                  # MIT-BIH sampling frequency\n",
    "    WINDOW_SECONDS = 1.0      # 1-second windows\n",
    "    TIME_STEPS = int(FS * WINDOW_SECONDS)  # 360\n",
    "\n",
    "    assert TIME_STEPS == cfg.TIME_STEPS, (\n",
    "        f\"TIME_STEPS from preprocessing = {TIME_STEPS}, \"\n",
    "        f\"but cfg.TIME_STEPS = {cfg.TIME_STEPS}. \"\n",
    "        \"Adjust one of them so they match.\"\n",
    "    )\n",
    "\n",
    "    # Mapping of beat symbols -> class index\n",
    "    symbol_to_class = {\n",
    "        'N': 0,  # normal-related (N, LBBB, RBBB, etc.)\n",
    "        'L': 0,\n",
    "        'R': 0,\n",
    "        'V': 1,  # ventricular\n",
    "        'A': 2,  # supraventricular / atrial\n",
    "        '/': 3,  # paced\n",
    "        'F': 4,  # fusion / other\n",
    "    }\n",
    "\n",
    "    # To avoid OOM, cap beats per record\n",
    "    MAX_BEATS_PER_RECORD = 500   # tweak this if you want more/less\n",
    "\n",
    "    # ---------- 3) Helper to find record IDs ----------\n",
    "    def load_record_list_from_hea(db_dir: str):\n",
    "        files = os.listdir(db_dir)\n",
    "        hea_files = [f for f in files if f.endswith(\".hea\")]\n",
    "        record_ids = sorted([os.path.splitext(f)[0] for f in hea_files])\n",
    "        print(f\"Found {len(record_ids)} records in {db_dir}\")\n",
    "        return record_ids\n",
    "\n",
    "    # ---------- 4) Extract segments from one record ----------\n",
    "    def extract_segments_from_record(record_id: str, db_dir: str):\n",
    "        \"\"\"\n",
    "        Returns segments: (K, TIME_STEPS, 2)\n",
    "                labels:   (K,)\n",
    "                groups:   (K,)\n",
    "        \"\"\"\n",
    "        rec_path = os.path.join(db_dir, record_id)\n",
    "\n",
    "        record = wfdb.rdrecord(rec_path)\n",
    "        ann = wfdb.rdann(rec_path, 'atr')\n",
    "\n",
    "        sig = record.p_signal  # (num_samples, num_leads)\n",
    "        num_samples, num_leads = sig.shape\n",
    "        if num_leads < 2:\n",
    "            return None, None, None\n",
    "\n",
    "        half_win = TIME_STEPS // 2\n",
    "        segments = []\n",
    "        labels = []\n",
    "        groups = []\n",
    "\n",
    "        # We’ll shuffle indices so we only keep up to MAX_BEATS_PER_RECORD\n",
    "        beat_indices = np.arange(len(ann.sample))\n",
    "        np.random.shuffle(beat_indices)\n",
    "\n",
    "        kept = 0\n",
    "        for idx_i in beat_indices:\n",
    "            if kept >= MAX_BEATS_PER_RECORD:\n",
    "                break\n",
    "\n",
    "            idx = ann.sample[idx_i]\n",
    "            sym = ann.symbol[idx_i]\n",
    "            if sym not in symbol_to_class:\n",
    "                continue\n",
    "\n",
    "            start = idx - half_win\n",
    "            end = idx + half_win\n",
    "\n",
    "            if start < 0 or end > num_samples:\n",
    "                continue\n",
    "\n",
    "            seg = sig[start:end, :2]  # (T, 2)\n",
    "            if seg.shape[0] != TIME_STEPS:\n",
    "                continue\n",
    "\n",
    "            segments.append(seg.astype(np.float32))\n",
    "            labels.append(symbol_to_class[sym])\n",
    "            groups.append(record_id)\n",
    "            kept += 1\n",
    "\n",
    "        if len(segments) == 0:\n",
    "            return None, None, None\n",
    "\n",
    "        return (\n",
    "            np.stack(segments, axis=0),           # (K, T, 2)\n",
    "            np.array(labels, dtype=np.int64),     # (K,)\n",
    "            np.array(groups)                      # (K,)\n",
    "        )\n",
    "\n",
    "    # ---------- 5) Loop over MITDB records ----------\n",
    "    print(\"=== Extracting labeled segments from MIT-BIH Arrhythmia (mitdb) ===\")\n",
    "    mit_records = load_record_list_from_hea(MITDB_DIR)\n",
    "\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_groups = []\n",
    "\n",
    "    for rec in mit_records:\n",
    "        print(f\"Processing record {rec}...\")\n",
    "        X_rec, y_rec, g_rec = extract_segments_from_record(rec, MITDB_DIR)\n",
    "        if X_rec is None:\n",
    "            print(f\"  No usable beats for record {rec}, skipping.\")\n",
    "            continue\n",
    "        all_X.append(X_rec)\n",
    "        all_y.append(y_rec)\n",
    "        all_groups.append(g_rec)\n",
    "\n",
    "    X = np.concatenate(all_X, axis=0)\n",
    "    y = np.concatenate(all_y, axis=0)\n",
    "    groups = np.concatenate(all_groups, axis=0)\n",
    "\n",
    "    print(\"\\nFinal dataset shapes:\")\n",
    "    print(\"X:\", X.shape, \"y:\", y.shape, \"groups:\", groups.shape)\n",
    "    print(\"Unique labels:\", np.unique(y))\n",
    "\n",
    "    np.save(X_PATH, X)\n",
    "    np.save(Y_PATH, y)\n",
    "    np.save(G_PATH, groups)\n",
    "\n",
    "    print(\"\\nSaved X.npy, y.npy, groups.npy in\", DATA_ROOT)\n",
    "    print(\"Preprocessing done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999ff79-5b9d-4b00-b046-6347c516e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 3. DATASET\n",
    "# =====================================================\n",
    "class ECGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects:\n",
    "        X.npy: shape (N, TIME_STEPS, NUM_LEADS)\n",
    "        y.npy: shape (N,)\n",
    "        groups.npy (optional): shape (N,) with group IDs (e.g., record or patient).\n",
    "\n",
    "    If groups.npy exists, we perform group-wise splitting so that no group appears\n",
    "    in more than one split (patient-independent evaluation).\n",
    "\n",
    "    Otherwise, we fall back to a simple random split.\n",
    "    \"\"\"\n",
    "    def __init__(self, split: str = \"train\"):\n",
    "        assert split in [\"train\", \"val\", \"test\"]\n",
    "        self.split = split\n",
    "\n",
    "        X, y, groups = self.load_arrays()\n",
    "\n",
    "        if groups is not None:\n",
    "            # Group-wise split (e.g., by record or patient ID)\n",
    "            unique_groups = np.unique(groups)\n",
    "            np.random.shuffle(unique_groups)\n",
    "\n",
    "            n_groups = len(unique_groups)\n",
    "            n_train = int(cfg.TRAIN_VAL_TEST_SPLIT[0] * n_groups)\n",
    "            n_val = int(cfg.TRAIN_VAL_TEST_SPLIT[1] * n_groups)\n",
    "            # remaining groups go to test\n",
    "            train_groups = set(unique_groups[:n_train])\n",
    "            val_groups = set(unique_groups[n_train:n_train + n_val])\n",
    "            test_groups = set(unique_groups[n_train + n_val:])\n",
    "\n",
    "            if split == \"train\":\n",
    "                mask = np.isin(groups, list(train_groups))\n",
    "            elif split == \"val\":\n",
    "                mask = np.isin(groups, list(val_groups))\n",
    "            else:\n",
    "                mask = np.isin(groups, list(test_groups))\n",
    "\n",
    "            self.X = X[mask]\n",
    "            self.y = y[mask]\n",
    "        else:\n",
    "            # Sample-wise random split\n",
    "            n = len(X)\n",
    "            n_train = int(cfg.TRAIN_VAL_TEST_SPLIT[0] * n)\n",
    "            n_val = int(cfg.TRAIN_VAL_TEST_SPLIT[1] * n)\n",
    "            n_test = n - n_train - n_val\n",
    "\n",
    "            indices = np.arange(n)\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            train_idx = indices[:n_train]\n",
    "            val_idx = indices[n_train:n_train + n_val]\n",
    "            test_idx = indices[n_train + n_val:]\n",
    "\n",
    "            if split == \"train\":\n",
    "                self.X = X[train_idx]\n",
    "                self.y = y[train_idx]\n",
    "            elif split == \"val\":\n",
    "                self.X = X[val_idx]\n",
    "                self.y = y[val_idx]\n",
    "            else:\n",
    "                self.X = X[test_idx]\n",
    "                self.y = y[test_idx]\n",
    "\n",
    "        # Safety check on shapes\n",
    "        assert self.X.shape[1] == cfg.TIME_STEPS, \\\n",
    "            f\"Expected TIME_STEPS={cfg.TIME_STEPS}, got {self.X.shape[1]}\"\n",
    "        assert self.X.shape[2] == cfg.NUM_LEADS, \\\n",
    "            f\"Expected NUM_LEADS={cfg.NUM_LEADS}, got {self.X.shape[2]}\"\n",
    "\n",
    "    def load_arrays(self) -> Tuple[np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Loads X, y (and optionally groups) from disk.\n",
    "\n",
    "        You must create these files in a separate preprocessing step.\n",
    "        \"\"\"\n",
    "        x_path = os.path.join(cfg.DATA_ROOT, cfg.X_FILE)\n",
    "        y_path = os.path.join(cfg.DATA_ROOT, cfg.Y_FILE)\n",
    "        assert os.path.exists(x_path), f\"Missing {x_path}\"\n",
    "        assert os.path.exists(y_path), f\"Missing {y_path}\"\n",
    "\n",
    "        X = np.load(x_path)  # (N, TIME_STEPS, NUM_LEADS)\n",
    "        y = np.load(y_path)  # (N,)\n",
    "\n",
    "        groups_path = os.path.join(cfg.DATA_ROOT, cfg.GROUP_FILE)\n",
    "        if os.path.exists(groups_path):\n",
    "            groups = np.load(groups_path)\n",
    "        else:\n",
    "            groups = None\n",
    "\n",
    "        return X, y, groups\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            x: torch.Tensor, shape (NUM_LEADS, TIME_STEPS)\n",
    "               (leads as channels, time as sequence)\n",
    "            y: torch.LongTensor, scalar class label\n",
    "        \"\"\"\n",
    "        x = self.X[idx].astype(np.float32)  # (T, L)\n",
    "        y = int(self.y[idx])\n",
    "\n",
    "        # Per-segment, per-lead normalization (z-score)\n",
    "        # shape (T, L)\n",
    "        mean = x.mean(axis=0, keepdims=True)\n",
    "        std = x.std(axis=0, keepdims=True) + 1e-8\n",
    "        x = (x - mean) / std\n",
    "\n",
    "        # Convert to (C, T) for Conv1d (channels = leads)\n",
    "        x = torch.from_numpy(x).permute(1, 0)  # (L, T)\n",
    "\n",
    "        label = torch.tensor(y, dtype=torch.long)\n",
    "        return x, label\n",
    "\n",
    "\n",
    "def get_dataloaders():\n",
    "    train_ds = ECGDataset(split=\"train\")\n",
    "    val_ds = ECGDataset(split=\"val\")\n",
    "    test_ds = ECGDataset(split=\"test\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=cfg.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=cfg.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c4778-fb81-4816-a04e-597ee656f583",
   "metadata": {},
   "source": [
    "**Baseline Architecture**\n",
    "\n",
    "Our baseline classifier is a lightweight 1D convolutional neural network, consisting of:\n",
    "- Three Conv1D → ReLU → BatchNorm blocks\n",
    "- Global Average Pooling\n",
    "- Two fully connected layers\n",
    "- Softmax output over 5 classes\n",
    "This model directly maps raw ECG windows (360 × 2) to arrhythmia classes.\n",
    "\n",
    "**Baseline Training Procedure**\n",
    "\n",
    "- Loss: Cross-Entropy\n",
    "- Optimizer: Adam (1e-3)\n",
    "- Batch Size: 64\n",
    "- Epochs (Testing Runs): 5\n",
    "- Epochs (Actual Run): 20\n",
    "- Device: CPU\n",
    "\n",
    "We train the baseline on the training set and evaluate on validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b393bcc-bf7c-4341-9217-a70c476339f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 4. BASELINE CNN CLASSIFIER\n",
    "# =====================================================\n",
    "class BaselineCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Chose to setup as a Simple 1D CNN baseline\n",
    "    Input: (batch, C=NUM_LEADS, T=TIME_STEPS)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_leads: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(num_leads, 32, kernel_size=7, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)  # -> (B, 128, 1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5cfe4-5fed-4c15-8b9e-619f07e82dfc",
   "metadata": {},
   "source": [
    "**CDAE Motivation**\n",
    "\n",
    "The CDAE improves feature robustness by learning to reconstruct clean ECG signals from intentionally corrupted inputs. This unsupervised pre-training has the goal of being able to:\n",
    "- Improve generalization\n",
    "- Denoise heartbeat morphology\n",
    "- Provide a more stable representation than raw numerical values\n",
    "\n",
    "**Denoising Strategy**\n",
    "\n",
    "Our strategy for denoising by adding Gaussian noise with randomly sampled standard deviation uses the following equation:\n",
    "\n",
    "$x_{noisy}=x+N(0,\\sigma^2), \\sigma \\in [0.01,0.15]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1671a1c6-ea59-45be-9543-4c34fe128d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 5. CDAE: AUTOENCODER + CLASSIFIER HEAD\n",
    "# =====================================================\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_leads: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(num_leads, 32, kernel_size=7, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "            # Output: (B, 128, T/4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_leads: int, input_time: int):\n",
    "        super().__init__()\n",
    "        self.input_time = input_time\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose1d(\n",
    "                128, 64, kernel_size=4, stride=2, padding=1\n",
    "            ),  # upsample x2\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(\n",
    "                64, 32, kernel_size=4, stride=2, padding=1\n",
    "            ),  # upsample x2\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, num_leads, kernel_size=7, padding=3)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x_hat = self.net(z)\n",
    "        # Adjust to exact TIME_STEPS if off by 1\n",
    "        if x_hat.shape[-1] > self.input_time:\n",
    "            x_hat = x_hat[..., :self.input_time]\n",
    "        elif x_hat.shape[-1] < self.input_time:\n",
    "            pad = self.input_time - x_hat.shape[-1]\n",
    "            x_hat = nn.functional.pad(x_hat, (0, pad))\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "class CDAEClassifier(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_pooled = self.pool(z)\n",
    "        logits = self.fc(z_pooled)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec505cd-00cf-4b74-ab96-bc98caa5c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 6. TRAINING UTILITIES\n",
    "# =====================================================\n",
    "def add_gaussian_noise(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise with std drawn uniformly from [AE_NOISE_STD_MIN, AE_NOISE_STD_MAX].\n",
    "    \"\"\"\n",
    "    std_min = cfg.AE_NOISE_STD_MIN\n",
    "    std_max = cfg.AE_NOISE_STD_MAX\n",
    "    if std_max <= 0:\n",
    "        return x\n",
    "    noise_std = np.random.uniform(std_min, std_max)\n",
    "    return x + torch.randn_like(x) * noise_std\n",
    "\n",
    "\n",
    "def train_epoch_classifier(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_classifier(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def train_autoencoder(encoder: Encoder, decoder: Decoder,\n",
    "                      train_loader, val_loader):\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    ae_params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "    optimizer = optim.Adam(ae_params, lr=cfg.LR_AE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(cfg.NUM_EPOCHS_AE):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        train_loss = 0.0\n",
    "        total = 0\n",
    "\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            noisy_x = add_gaussian_noise(x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            z = encoder(noisy_x)\n",
    "            x_hat = decoder(z)\n",
    "            loss = criterion(x_hat, x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            total += x.size(0)\n",
    "\n",
    "        train_loss /= total\n",
    "\n",
    "        # Validation reconstruction loss\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        val_loss = 0.0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, _ in val_loader:\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                noisy_x = add_gaussian_noise(x)\n",
    "                z = encoder(noisy_x)\n",
    "                x_hat = decoder(z)\n",
    "                loss = criterion(x_hat, x)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "                val_total += x.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        print(f\"[AE] Epoch {epoch+1}/{cfg.NUM_EPOCHS_AE} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b6e77df-dfbb-4a79-b6e3-457d3a286645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 7. END-TO-END EXPERIMENTS\n",
    "# =====================================================\n",
    "def run_baseline_experiment(train_loader, val_loader, test_loader):\n",
    "    model = BaselineCNN(cfg.NUM_LEADS, cfg.NUM_CLASSES).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.LR_BASELINE)\n",
    "\n",
    "    print(\"=== Training Baseline CNN ===\")\n",
    "    for epoch in range(cfg.NUM_EPOCHS_BASELINE):\n",
    "        train_loss, train_acc = train_epoch_classifier(\n",
    "            model, train_loader, criterion, optimizer\n",
    "        )\n",
    "        val_loss, val_acc = eval_classifier(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"[Baseline] Epoch {epoch+1}/{cfg.NUM_EPOCHS_BASELINE} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "    test_loss, test_acc = eval_classifier(model, test_loader, criterion)\n",
    "    print(f\"[Baseline] Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_cdae_experiment(train_loader, val_loader, test_loader):\n",
    "    # 1) Pretrain Autoencoder\n",
    "    encoder = Encoder(cfg.NUM_LEADS)\n",
    "    decoder = Decoder(cfg.NUM_LEADS, cfg.TIME_STEPS)\n",
    "\n",
    "    print(\"=== Pretraining CDAE Autoencoder ===\")\n",
    "    train_autoencoder(encoder, decoder, train_loader, val_loader)\n",
    "\n",
    "    # 2) Attach classifier head\n",
    "    model = CDAEClassifier(encoder, cfg.NUM_CLASSES).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Phase 1: freeze encoder, train classifier head\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=cfg.LR_CLASSIFIER\n",
    "    )\n",
    "\n",
    "    print(\"=== Training CDAE Classifier (frozen encoder) ===\")\n",
    "    for epoch in range(cfg.CDAE_FREEZE_EPOCHS):\n",
    "        train_loss, train_acc = train_epoch_classifier(\n",
    "            model, train_loader, criterion, optimizer\n",
    "        )\n",
    "        val_loss, val_acc = eval_classifier(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"[CDAE-Frozen] Epoch {epoch+1}/{cfg.CDAE_FREEZE_EPOCHS} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Phase 2: unfreeze encoder and fine-tune full network\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=cfg.LR_CLASSIFIER_FINE_TUNE\n",
    "    )\n",
    "\n",
    "    print(\"=== Fine-tuning CDAE Classifier (encoder + head) ===\")\n",
    "    for epoch in range(cfg.CDAE_FREEZE_EPOCHS, cfg.NUM_EPOCHS_CDAE):\n",
    "        train_loss, train_acc = train_epoch_classifier(\n",
    "            model, train_loader, criterion, optimizer\n",
    "        )\n",
    "        val_loss, val_acc = eval_classifier(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"[CDAE-Fine] Epoch {epoch+1}/{cfg.NUM_EPOCHS_CDAE} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "    test_loss, test_acc = eval_classifier(model, test_loader, criterion)\n",
    "    print(f\"[CDAE] Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1718e-d207-4b61-9251-799008ba9919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Baseline CNN ===\n",
      "[Baseline] Epoch 1/5 | Train Loss: 0.0433 Acc: 0.9879 | Val Loss: 0.0661 Acc: 0.9770\n",
      "[Baseline] Epoch 2/5 | Train Loss: 0.0156 Acc: 0.9955 | Val Loss: 0.0443 Acc: 0.9868\n",
      "[Baseline] Epoch 3/5 | Train Loss: 0.0116 Acc: 0.9968 | Val Loss: 0.0620 Acc: 0.9794\n",
      "[Baseline] Epoch 4/5 | Train Loss: 0.0094 Acc: 0.9974 | Val Loss: 0.0775 Acc: 0.9726\n",
      "[Baseline] Epoch 5/5 | Train Loss: 0.0083 Acc: 0.9977 | Val Loss: 0.0323 Acc: 0.9931\n",
      "[Baseline] Test Loss: 0.0311 | Test Acc: 0.9939\n",
      "=== Pretraining CDAE Autoencoder ===\n",
      "[AE] Epoch 1/5 | Train Loss: 0.0183 | Val Loss: 0.0085\n",
      "[AE] Epoch 2/5 | Train Loss: 0.0069 | Val Loss: 0.0062\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 8. MAIN ENTRY POINT (for scripts) \n",
    "# =====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader, val_loader, test_loader = get_dataloaders()\n",
    "\n",
    "    # Baseline CNN experiment\n",
    "    baseline_model = run_baseline_experiment(train_loader, val_loader, test_loader)\n",
    "\n",
    "    # CDAE experiment\n",
    "    cdae_model = run_cdae_experiment(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07143cd9-8c55-4bb4-8723-dbb834b84ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
